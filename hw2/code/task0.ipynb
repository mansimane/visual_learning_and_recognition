{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "from datasets.factory import get_imdb\n",
    "import visdom\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "imdb = get_imdb('voc_2007_trainval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/VOCdevkit2007/VOC2007/JPEGImages/003998.jpg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.image_path_at(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[ 11,  59, 499, 306]], dtype=uint16),\n",
       " 'flipped': False,\n",
       " 'gt_classes': array([7], dtype=int32),\n",
       " 'gt_overlaps': <1x21 sparse matrix of type '<type 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'seg_areas': array([121272.], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = imdb._load_pascal_annotation('003998')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aeroplane',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'boat',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'person',\n",
       " 'pottedplant',\n",
       " 'sheep',\n",
       " 'sofa',\n",
       " 'train',\n",
       " 'tvmonitor')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_2007_trainval gt roidb loaded from /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "gt_roidb = imdb.gt_roidb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_2007_trainval gt roidb loaded from /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "wrote ss roidb to /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_selective_search_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "ss_roidb = imdb.selective_search_roidb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[ 11,  59, 499, 306],\n",
       "        [  0,  63, 499, 336],\n",
       "        [320, 161, 416, 281],\n",
       "        ...,\n",
       "        [369, 288, 412, 364],\n",
       "        [180, 300, 208, 331],\n",
       "        [328, 165, 368, 189]], dtype=int32), 'boxscores': array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.01060787],\n",
       "        [0.01053118],\n",
       "        [0.01023103]]), 'flipped': False, 'gt_classes': array([7, 0, 0, ..., 0, 0, 0], dtype=int32), 'gt_overlaps': <2853x21 sparse matrix of type '<type 'numpy.float32'>'\n",
       " \twith 2496 stored elements in Compressed Sparse Row format>, 'gt_vec': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32), 'seg_areas': array([121272.,      0.,      0., ...,      0.,      0.,      0.],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_roidb[2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_detections(im, dets):\n",
    "    \"\"\"Visual debugging of detections.\"\"\"\n",
    "    for i in range(np.minimum(10, dets.shape[0])):\n",
    "        bbox = tuple(int(np.round(x)) for x in dets[i, :4])\n",
    "        #score = dets[i, -1]\n",
    "        \n",
    "        cv2.rectangle(im, bbox[0:2], bbox[2:4], (0, 204, 0), 2)\n",
    "        cv2.putText(im, 'rank: %d' % (i), (bbox[0], bbox[1] + 15), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1.0, (0, 0, 255), thickness=1)\n",
    "    return im\n",
    "\n",
    "dets = ss_roidb[2018]['boxes']\n",
    "img = cv2.imread(imdb.image_path_at(2018))\n",
    "res_img = vis_detections(img, dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'window_361294280ee3ec'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = visdom.Visdom(server='http://localhost',port='8097')\n",
    "vis.text('Task 0, Proposals')\n",
    "vis.image(res_img.transpose((2,0,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(375, 500, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(type(res_img))\n",
    "# res_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  59 499 306]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'window_3612952b9bdff8'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dets = gt_roidb[2018]['boxes']\n",
    "print(gt_roidb[2018]['boxes'])\n",
    "img = cv2.imread(imdb.image_path_at(2018))\n",
    "gt_res_img = vis_detections(img, gt_dets)\n",
    "vis.image(gt_res_img.transpose((2,0,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
