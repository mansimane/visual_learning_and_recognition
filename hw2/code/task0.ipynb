{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "from datasets.factory import get_imdb\n",
    "import visdom\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "imdb = get_imdb('voc_2007_trainval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/VOCdevkit2007/VOC2007/JPEGImages/003998.jpg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.image_path_at(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[ 11,  59, 499, 306]], dtype=uint16),\n",
       " 'flipped': False,\n",
       " 'gt_classes': array([7], dtype=int32),\n",
       " 'gt_overlaps': <1x21 sparse matrix of type '<type 'numpy.float32'>'\n",
       " \twith 1 stored elements in Compressed Sparse Row format>,\n",
       " 'seg_areas': array([121272.], dtype=float32)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = imdb._load_pascal_annotation('003998')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aeroplane',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'boat',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorbike',\n",
       " 'person',\n",
       " 'pottedplant',\n",
       " 'sheep',\n",
       " 'sofa',\n",
       " 'train',\n",
       " 'tvmonitor')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_2007_trainval gt roidb loaded from /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "gt_roidb = imdb.gt_roidb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aeroplane': 0,\n",
       " 'bicycle': 1,\n",
       " 'bird': 2,\n",
       " 'boat': 3,\n",
       " 'bottle': 4,\n",
       " 'bus': 5,\n",
       " 'car': 6,\n",
       " 'cat': 7,\n",
       " 'chair': 8,\n",
       " 'cow': 9,\n",
       " 'diningtable': 10,\n",
       " 'dog': 11,\n",
       " 'horse': 12,\n",
       " 'motorbike': 13,\n",
       " 'person': 14,\n",
       " 'pottedplant': 15,\n",
       " 'sheep': 16,\n",
       " 'sofa': 17,\n",
       " 'train': 18,\n",
       " 'tvmonitor': 19}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0 \n",
    "class_to_idx = {}\n",
    "for cls in imdb.classes:\n",
    "    class_to_idx[cls] = i\n",
    "    i += 1\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011\n",
      "{'boxes': array([[ 68,   3, 391, 344]], dtype=uint16), 'gt_classes': array([12], dtype=int32), 'gt_overlaps': <1x21 sparse matrix of type '<type 'numpy.float32'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'seg_areas': array([110808.], dtype=float32), 'flipped': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/VOCdevkit2007/VOC2007/JPEGImages/009961.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(gt_roidb))\n",
    "    #TODO: return list of (image path, list(+ve class indices)) tuples\n",
    "print(gt_roidb[5010])\n",
    "imdb.image_path_at(5010)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_2007_trainval gt roidb loaded from /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(imdb, class_to_idx):\n",
    "    #TODO: return list of (image path, list(+ve class indices)) tuples\n",
    "    #You will be using this in IMDBDataset\n",
    "    gt_roidb = imdb.gt_roidb()\n",
    "    images = [None]*len(gt_roidb)\n",
    "    for i in range(len(gt_roidb)):\n",
    "        path = imdb.image_path_at(i)\n",
    "        cls = [c for c in gt_roidb[i]['gt_classes']]\n",
    "        images[i] = (path,cls)\n",
    "    return images\n",
    "imgs = make_dataset(imdb, class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/VOCdevkit2007/VOC2007/JPEGImages/000005.jpg',\n",
       " [9, 9, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc_2007_trainval gt roidb loaded from /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_gt_roidb.pkl\n",
      "wrote ss roidb to /home/ubuntu/code/visual_learning_and_recognition/hw2/code/data/cache/voc_2007_trainval_selective_search_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "ss_roidb = imdb.selective_search_roidb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[ 11,  59, 499, 306],\n",
       "        [  0,  63, 499, 336],\n",
       "        [320, 161, 416, 281],\n",
       "        ...,\n",
       "        [369, 288, 412, 364],\n",
       "        [180, 300, 208, 331],\n",
       "        [328, 165, 368, 189]], dtype=int32), 'boxscores': array([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.01060787],\n",
       "        [0.01053118],\n",
       "        [0.01023103]]), 'flipped': False, 'gt_classes': array([7, 0, 0, ..., 0, 0, 0], dtype=int32), 'gt_overlaps': <2853x21 sparse matrix of type '<type 'numpy.float32'>'\n",
       " \twith 2496 stored elements in Compressed Sparse Row format>, 'gt_vec': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32), 'seg_areas': array([121272.,      0.,      0., ...,      0.,      0.,      0.],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_roidb[2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_detections(im, dets):\n",
    "    \"\"\"Visual debugging of detections.\"\"\"\n",
    "    for i in range(np.minimum(10, dets.shape[0])):\n",
    "        bbox = tuple(int(np.round(x)) for x in dets[i, :4])\n",
    "        #score = dets[i, -1]\n",
    "        \n",
    "        cv2.rectangle(im, bbox[0:2], bbox[2:4], (0, 204, 0), 2)\n",
    "        cv2.putText(im, 'rank: %d' % (i), (bbox[0], bbox[1] + 15), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1.0, (0, 0, 255), thickness=1)\n",
    "    return im\n",
    "\n",
    "dets = ss_roidb[2018]['boxes']\n",
    "img = cv2.imread(imdb.image_path_at(2018))\n",
    "res_img = vis_detections(img, dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'window_361294280ee3ec'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis = visdom.Visdom(server='http://localhost',port='8097')\n",
    "vis.text('Task 0, Proposals')\n",
    "vis.image(res_img.transpose((2,0,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(375, 500, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(type(res_img))\n",
    "# res_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  59 499 306]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'window_3612952b9bdff8'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dets = gt_roidb[2018]['boxes']\n",
    "print(gt_roidb[2018]['boxes'])\n",
    "img = cv2.imread(imdb.image_path_at(2018))\n",
    "gt_res_img = vis_detections(img, gt_dets)\n",
    "vis.image(gt_res_img.transpose((2,0,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /home/ubuntu/.torch/models/alexnet-owt-4df8aa71.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features\n",
    "for param in model.features:\n",
    "    param.requires_grad = False\n",
    "# for param in model.parameters():\n",
    "#     print(param)\n",
    "    #param.requires_grad = False\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
